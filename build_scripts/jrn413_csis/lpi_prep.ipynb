{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CSIS LPI data for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 2011-2018 data\n",
    "lpi_path1 = \"/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/\"\n",
    "# 2019-present data\n",
    "lpi_path2 = \"/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/\"\n",
    "dest_path1 = \"/media/greg/jrn-DataProducts/JORNADA_IM/WIP_packages/210413002_CSIS_lpi_gap/\"\n",
    "#dest_path2 = \"/media/greg/jrn-DataProducts/JORNADA_IM/WIP_packages/210413005_CSIS_overhead_cover/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the earlier DAT and CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number LPI files in folder: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_12F.csv',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_12S.csv',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_13S.csv',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_11F.csv',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_13F.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_14F.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_14S.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_15F.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_15S.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_16F.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_16S.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_17F.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_17S.dat',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_18S.DAT',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_18F.DAT']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = [glob.glob(os.path.join(lpi_path1,'CSIS_LPI*.{0}'.format(e)), recursive=False) for e in ['csv', 'dat', 'DAT']]\n",
    "fns = sum(fns, []) # In case we end up with list of lists\n",
    "print('number LPI files in folder: ' + str(len(fns)))\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['study', 'year', 's', 'date', 'bk', 'p', 't', 'pt', 'top', 'ts', 'L1',\n",
      "       'L1s', 'L2', 'L2s', 'L3', 'L3s', 'SL', 'SLs', 'tH', 'tFrm', 'tP',\n",
      "       '1H 1Frm', '1P', '2H 2Frm', '2P', '3H 3Frm', '3P', 'sH sFrm', 'sP',\n",
      "       'rIn', 'readerName', 'Unnamed: 31', 'dIn', 'dataentryName',\n",
      "       'Unnamed: 34', 'Unnamed: 35'],\n",
      "      dtype='object')\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'topLayer', 'topLayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilSurface',\n",
      "       'soilSurface_status', 'comment', 'Recorder', 'Date Entered',\n",
      "       'Date Verified', 'Intials'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_dat = pd.read_fwf(fns[10], skiprows=44)\n",
    "df_csv = pd.read_csv(fns[1])\n",
    "print(df_dat.columns)\n",
    "print(df_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap_1 = {'s':'season','bk':'block','p':'plot','t':'transect','pt':'point',\n",
    "            'top':'toplayer','ts':'toplayer_status',\n",
    "            'L1':'layer1','L1s':'layer1_status',\n",
    "            'L2':'layer2','L2s':'layer2_status',\n",
    "            'L3':'layer3','L3s':'layer3_status',\n",
    "            'SL':'soilsurface','SLs':'soilsurface_status',\n",
    "            'tH':'toplayer_habit','tFrm':'toplayer_form','tP':'toplayer_carbon',\n",
    "            '1H':'layer1_habit','1Frm':'layer1_form','1P':'layer1_carbon',\n",
    "            '2H':'layer2_habit','2Frm':'layer2_form','2P':'layer2_carbon',\n",
    "            '3H':'layer3_habit','3Frm':'layer3_form','3P':'layer3_carbon',\n",
    "            'sH':'soilsurface_habit','sFrm':'soilsurface_form','sP':'soilsurface_carbon'}\n",
    "\n",
    "colmap_2 = {'Date':'date','Block':'block','Plot':'plot',\n",
    "            'topLayer':'toplayer','topLayer_status':'toplayer_status',\n",
    "            'soilSurface':'soilsurface','soilSurface_status':'soilsurface_status',\n",
    "            'Comment':'comment'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_12F.csv\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6120, 23)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'comment', 'Recorder', 'Date Entered',\n",
      "       'Date Verified', 'Intials'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_12S.csv\n",
      "1\n",
      "(6120, 23)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'comment', 'Recorder', 'Date Entered',\n",
      "       'Date Verified', 'Intials'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_13S.csv\n",
      "1\n",
      "(6120, 23)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'comment', 'Recorder', 'Date Entered',\n",
      "       'Date Verified', 'Intials'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_11F.csv\n",
      "1\n",
      "(6000, 23)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'comment', 'Recorder', 'Date Entered',\n",
      "       'Date Verified', 'Intials'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_13F.dat\n",
      "45\n",
      "(11716, 42)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:32', 'Unnamed:33',\n",
      "       'dIn', 'dataentryName', 'Unnamed:36', 'Unnamed:37', 'Unnamed:38'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_14F.dat\n",
      "45\n",
      "(17901, 41)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_14S.dat\n",
      "45\n",
      "(12095, 39)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:32', 'dIn',\n",
      "       'dataentryName', 'Unnamed:35'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_15F.dat\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17884, 41)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_15S.dat\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14179, 41)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_16F.dat\n",
      "45\n",
      "(17917, 41)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:29', 'Unnamed:30',\n",
      "       'dIn', 'dataentryName', 'Unnamed:33', 'Unnamed:34'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_16S.dat\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17892, 40)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_17F.dat\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17888, 40)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_17S.dat\n",
      "45\n",
      "(17902, 41)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:31', 'dIn',\n",
      "       'dataentryName', 'Unnamed:34', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_18S.DAT\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17895, 40)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:32', 'dIn',\n",
      "       'dataentryName', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_data/CSIS_LPI_18F.DAT\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257792/980981662.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17896, 40)\n",
      "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
      "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
      "       'soilsurface_status', 'toplayer_habit', 'toplayer_form',\n",
      "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
      "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
      "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
      "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:32', 'dIn',\n",
      "       'dataentryName', 'Unnamed:35', 'Unnamed:36'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in the text files\n",
    "frames = []\n",
    "\n",
    "for f in fns:\n",
    "    print(f)\n",
    "    # Get number of lines to skip, use a windoze encoding for these old files\n",
    "    with open(f, 'r', encoding='cp1252') as fo:\n",
    "        lines = [line.rstrip() for line in fo]\n",
    "    start_match = pd.Series(lines).str.contains('^CSIS-LPI')\n",
    "    skip_no = start_match[start_match].index.values.min()\n",
    "    print(skip_no)\n",
    "    # Read csv and append to frames list (note these csvs have extra spaces)\n",
    "    if skip_no==45:\n",
    "        # These are old dat files and the header doesn't really match the columns - \n",
    "        # some right, some left justified. Steps below parse and correct col headers\n",
    "        col_raw = pd.read_fwf(f, skiprows=(skip_no-1), nrows=0,\n",
    "                              index_col=False, encoding='cp1252').columns.tolist()\n",
    "        cols = [c.replace('Unnamed: ', 'Unnamed:') for c in col_raw]\n",
    "        # join/splits to split multiple column headers read in as one\n",
    "        cols = [' '.join(c.split()) for c in cols] # drop multiple spaces\n",
    "        cols = ' '.join(cols).split(' ')  # split on any single spaced col header\n",
    "        # Now read past the header row and use the corrected header\n",
    "        # Big infer rows param to account for some unpredictable errors in data entry\n",
    "        df = pd.read_fwf(f, skiprows=(skip_no), infer_nrows=10000, na_values=['.'], names=cols,\n",
    "                         index_col=False, encoding='cp1252')\n",
    "        # Rename some columns\n",
    "        df = df.rename(columns=colmap_1)\n",
    "        print(df.shape)\n",
    "        print(df.columns)\n",
    "    else:\n",
    "        # Read file and rename\n",
    "        df = pd.read_csv(f, na_values=['.'], encoding='cp1252')\n",
    "        df = df.rename(columns=colmap_2)\n",
    "        print(df.shape)\n",
    "        print(df.columns)\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate dfs into one\n",
    "df1 = pd.concat(frames, axis=0, ignore_index=True)\n",
    "# Set dates\n",
    "df1.date = pd.to_datetime(df1.date, format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205525 entries, 0 to 205524\n",
      "Data columns (total 52 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   study               205525 non-null  object        \n",
      " 1   year                205525 non-null  int64         \n",
      " 2   season              205525 non-null  object        \n",
      " 3   date                205525 non-null  datetime64[ns]\n",
      " 4   block               205525 non-null  int64         \n",
      " 5   plot                205525 non-null  object        \n",
      " 6   transect            205525 non-null  int64         \n",
      " 7   point               205525 non-null  int64         \n",
      " 8   toplayer            204984 non-null  object        \n",
      " 9   toplayer_status     77561 non-null   object        \n",
      " 10  layer1              81364 non-null   object        \n",
      " 11  layer1_status       7820 non-null    object        \n",
      " 12  layer2              5432 non-null    object        \n",
      " 13  layer2_status       229 non-null     object        \n",
      " 14  layer3              143 non-null     object        \n",
      " 15  layer3_status       3 non-null       object        \n",
      " 16  soilsurface         204716 non-null  object        \n",
      " 17  soilsurface_status  2545 non-null    object        \n",
      " 18  comment             506 non-null     object        \n",
      " 19  Recorder            24359 non-null   object        \n",
      " 20  Date Entered        24358 non-null   object        \n",
      " 21  Date Verified       24358 non-null   object        \n",
      " 22  Intials             24358 non-null   object        \n",
      " 23  toplayer_habit      71086 non-null   object        \n",
      " 24  toplayer_form       180801 non-null  object        \n",
      " 25  toplayer_carbon     71395 non-null   object        \n",
      " 26  layer1_habit        6956 non-null    object        \n",
      " 27  layer1_form         22587 non-null   object        \n",
      " 28  layer1_carbon       7016 non-null    object        \n",
      " 29  layer2_habit        213 non-null     object        \n",
      " 30  layer2_form         990 non-null     object        \n",
      " 31  layer2_carbon       215 non-null     object        \n",
      " 32  layer3_habit        3 non-null       object        \n",
      " 33  layer3_form         11 non-null      object        \n",
      " 34  layer3_carbon       3 non-null       object        \n",
      " 35  soilsurface_habit   2218 non-null    object        \n",
      " 36  soilsurface_form    78414 non-null   object        \n",
      " 37  soilsurface_carbon  2221 non-null    object        \n",
      " 38  rIn                 181164 non-null  object        \n",
      " 39  readerName          181165 non-null  object        \n",
      " 40  Unnamed:32          19458 non-null   object        \n",
      " 41  Unnamed:33          29633 non-null   object        \n",
      " 42  dIn                 181164 non-null  object        \n",
      " 43  dataentryName       181165 non-null  object        \n",
      " 44  Unnamed:36          79570 non-null   object        \n",
      " 45  Unnamed:37          0 non-null       float64       \n",
      " 46  Unnamed:38          0 non-null       float64       \n",
      " 47  Unnamed:31          34254 non-null   object        \n",
      " 48  Unnamed:34          121563 non-null  object        \n",
      " 49  Unnamed:35          139437 non-null  object        \n",
      " 50  Unnamed:29          9558 non-null    object        \n",
      " 51  Unnamed:30          17917 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(45)\n",
      "memory usage: 81.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>block</th>\n",
       "      <th>plot</th>\n",
       "      <th>transect</th>\n",
       "      <th>point</th>\n",
       "      <th>toplayer</th>\n",
       "      <th>toplayer_status</th>\n",
       "      <th>...</th>\n",
       "      <th>dIn</th>\n",
       "      <th>dataentryName</th>\n",
       "      <th>Unnamed:36</th>\n",
       "      <th>Unnamed:37</th>\n",
       "      <th>Unnamed:38</th>\n",
       "      <th>Unnamed:31</th>\n",
       "      <th>Unnamed:34</th>\n",
       "      <th>Unnamed:35</th>\n",
       "      <th>Unnamed:29</th>\n",
       "      <th>Unnamed:30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSIS-LPI</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSIS-LPI</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSIS-LPI</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSIS-LPI</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSIS-LPI</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      study  year season       date  block plot  transect  point toplayer  \\\n",
       "0  CSIS-LPI  2012      F 2012-09-06      1    A         1      0     NONE   \n",
       "1  CSIS-LPI  2012      F 2012-09-06      1    A         1     50     NONE   \n",
       "2  CSIS-LPI  2012      F 2012-09-06      1    A         1    100     NONE   \n",
       "3  CSIS-LPI  2012      F 2012-09-06      1    A         1    150     NONE   \n",
       "4  CSIS-LPI  2012      F 2012-09-06      1    A         1    200     NONE   \n",
       "\n",
       "  toplayer_status  ...  dIn dataentryName Unnamed:36 Unnamed:37 Unnamed:38  \\\n",
       "0             NaN  ...  NaN           NaN        NaN        NaN        NaN   \n",
       "1             NaN  ...  NaN           NaN        NaN        NaN        NaN   \n",
       "2             NaN  ...  NaN           NaN        NaN        NaN        NaN   \n",
       "3             NaN  ...  NaN           NaN        NaN        NaN        NaN   \n",
       "4             NaN  ...  NaN           NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed:31 Unnamed:34 Unnamed:35 Unnamed:29 Unnamed:30  \n",
       "0        NaN        NaN        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in recent Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number LPI files in folder: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2019S.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2019F.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2020F.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2020S.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2021F.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2021S.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2022S.xlsx',\n",
       " '/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2022F.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first list the files\n",
    "fns = glob.glob(os.path.join(lpi_path2,'Data_CSIS_LPI*.xlsx'), recursive=False)\n",
    "#fns = sum(fns, []) # In case we end up with list of lists\n",
    "print('number LPI files in folder: ' + str(len(fns)))\n",
    "# Drop the 2023 data for now\n",
    "fns = [f for f in fns if '2023' not in f]\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap_3 = {'intercept':'point','top_layer':'toplayer','layer-1':'layer1',\n",
    "            'layer-2':'layer2','layer-3':'layer3','soil_surface':'soilsurface'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2019S.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pq_2019S_LPI\n",
      "(17886, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2019F.xlsx\n",
      "pq_2019F_LPI\n",
      "(17892, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2020F.xlsx\n",
      "pq_2020F_LPI\n",
      "(17460, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2020S.xlsx\n",
      "pq_2020S_LPI\n",
      "(17907, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2021F.xlsx\n",
      "pq_2021F_LPI\n",
      "(17496, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2021S.xlsx\n",
      "pq_2021S_LPI\n",
      "(8536, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2022S.xlsx\n",
      "pq_CSIS_LPI\n",
      "(17585, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n",
      "/media/greg/jrn-DataArchive/Data_ENT/LTER/_Entry/CSIS/csis-VegTran/_compiled/Data_CSIS_LPI-Gap_2022F.xlsx\n",
      "pq_CSIS_LPI\n",
      "(17463, 14)\n",
      "Index(['year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
      "       'toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface', 'comment',\n",
      "       'study'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in the excel files\n",
    "frames = []\n",
    "\n",
    "for f in fns:\n",
    "    print(f)\n",
    "    # Find the sheet we need (they vary year to year)\n",
    "    sheet = [s for s in pd.ExcelFile(f).sheet_names if 'pq' in s and 'LPI' in s][0]\n",
    "    print(sheet)\n",
    "    # Header rows are variable. Read first 20 lines and find header row (contains \n",
    "    # 'year') to set skiprows parameter\n",
    "    df_head = pd.read_excel(f, sheet, nrows=20)\n",
    "    header_loc = df_head[df_head == 'year'].dropna(axis=1, how='all').dropna(how='all')\n",
    "    if header_loc.empty:\n",
    "        skip = None # Don't skip anything if we get an empty df\n",
    "    else:\n",
    "        skip = header_loc.index.item() + 1\n",
    "    # Now read the file\n",
    "    df = pd.read_excel(f, sheet_name=sheet, skiprows=skip)\n",
    "    # Rename columns and replace values\n",
    "    df = df.rename(columns=colmap_3)\n",
    "    df.season = df.season.replace({'Spring':'S','Fall':'F'})\n",
    "    df['study'] = 'CSIS-LPI'\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate dfs into one\n",
    "df2 = pd.concat(frames, axis=0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>block</th>\n",
       "      <th>plot</th>\n",
       "      <th>transect</th>\n",
       "      <th>point</th>\n",
       "      <th>toplayer</th>\n",
       "      <th>layer1</th>\n",
       "      <th>layer2</th>\n",
       "      <th>layer3</th>\n",
       "      <th>soilsurface</th>\n",
       "      <th>comment</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSIS-LPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSIS-LPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSIS-LPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSIS-LPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSIS-LPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year season       date  block plot  transect  point toplayer layer1 layer2  \\\n",
       "0  2019      S 2019-04-12      1    A         1    0.0     NONE    NaN    NaN   \n",
       "1  2019      S 2019-04-12      1    A         1   25.0     NONE    NaN    NaN   \n",
       "2  2019      S 2019-04-12      1    A         1   50.0     NONE    NaN    NaN   \n",
       "3  2019      S 2019-04-12      1    A         1   75.0     NONE    NaN    NaN   \n",
       "4  2019      S 2019-04-12      1    A         1  100.0     NONE    NaN    NaN   \n",
       "\n",
       "  layer3 soilsurface comment     study  \n",
       "0    NaN           S     NaN  CSIS-LPI  \n",
       "1    NaN           S     NaN  CSIS-LPI  \n",
       "2    NaN           S     NaN  CSIS-LPI  \n",
       "3    NaN           S     NaN  CSIS-LPI  \n",
       "4    NaN           S     NaN  CSIS-LPI  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
       "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
       "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
       "       'soilsurface_status', 'comment', 'Recorder', 'Date Entered',\n",
       "       'Date Verified', 'Intials', 'toplayer_habit', 'toplayer_form',\n",
       "       'toplayer_carbon', 'layer1_habit', 'layer1_form', 'layer1_carbon',\n",
       "       'layer2_habit', 'layer2_form', 'layer2_carbon', 'layer3_habit',\n",
       "       'layer3_form', 'layer3_carbon', 'soilsurface_habit', 'soilsurface_form',\n",
       "       'soilsurface_carbon', 'rIn', 'readerName', 'Unnamed:32', 'Unnamed:33',\n",
       "       'dIn', 'dataentryName', 'Unnamed:36', 'Unnamed:37', 'Unnamed:38',\n",
       "       'Unnamed:31', 'Unnamed:34', 'Unnamed:35', 'Unnamed:29', 'Unnamed:30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['study', 'year', 'season', 'date', 'block', 'plot', 'transect', 'point',\n",
    "       'toplayer', 'toplayer_status', 'layer1', 'layer1_status', 'layer2',\n",
    "       'layer2_status', 'layer3', 'layer3_status', 'soilsurface',\n",
    "       'soilsurface_status', 'comment']\n",
    "df = df.loc[:,keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a few corrections before writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toplayer': array(['NONE', 'PRGL', 'SPOR1', 'XASA', 'ZIGR', 'BOER', 'BOER ', 'MUPO',\n",
       "        'ARIS1', 'CABA', 'XASA ', 'YUEL', 'PRGL ', 'MUPO ', 'SPOR1 ',\n",
       "        'SAKA', 'KRLA', 'CHIN', 'CRPO', 'DAPU', 'ERAB', 'CAJA', 'MISS',\n",
       "        'CRPO ', 'SOEL', nan, 'EPTR', 'EUAL', 'LATR', 'SPFL', 'NONE ',\n",
       "        'ATCA', 'XANT1', 'SPCO', 'BOBA', 'MOCE', 'EUMI', 'BOSP', 'TILA',\n",
       "        'PORT1', 'KAPA', 'ALIN', 'BOAR', 'PAHI', 'PEPA', 'ARAD', 'PEAN',\n",
       "        'SPAI', 'BRFA', 'TAAU', 'TRTE', 'EUSE', 'DECO', 'VEEN', 'EUSR',\n",
       "        'BOUT1', 'EUDE', 'BRAR', 'SELE', 'EUGL', 'PECT1', 'KALL1', 'POOL',\n",
       "        'MUSQ', 'HOGL', 'TALI1', 'EUPH1', 'TECO', 'ARPU', 'DIWI', 'SPIN',\n",
       "        'BAMU', 'ARHA', 'ARPE', 'DANA', 'ARNE', 'SAHA', 'PROB1', 'ZIAC',\n",
       "        'POMU', 'HODR', 'CONMD', 'BAAB', 'ERPE', 'SPCR', 'APRA', 'UKGRS',\n",
       "        'ARWR', 'PRGLS', 'AMPA', 'BOER1', 'BRAC1', 'ERLE', 'ERTE', 'ASAL',\n",
       "        'NAHI', 'CAHU', 'TAAN', 'ARPA', 'DYPE', 'CRYP1', 'ASTE', 'DYAC',\n",
       "        'SILE', 'HEHU', 'NYCT1', 'DEPI', 'LIVE', 'CRCR', 'POPA', 'PLPA',\n",
       "        'MATA', 'CRPU', 'CRMI', 'ARTE', 'YUELL', 'ACWR', 'LYBE', 'SPOR1B',\n",
       "        'PRGLD', 'XASAD', 'SPFLD', 'SPOR1D', 'BOERD', 'ARIS1D', 'SELED',\n",
       "        'MUPOD', 'ASNU', 'BOERB', 'CRPOD', 'DAPUD', 'SAKAD', 'DEPID',\n",
       "        'YUELD', 'ARPUD', 'NAHID', 'ARIS1B', 'XANT1D', 'LIVED', 'ERTR',\n",
       "        'MUPOB', 'DIWID', 'APRAD', 'SPCOD', 'ZIGRD', 'MEPU', 'CRYP1D',\n",
       "        'CRCRD', 'BAMUD', 'CAJAD', 'KRLAD', 'MEPUD', 'COAU', 'PHIT',\n",
       "        'BOBAD', 'CRAN', 'STEX', 'SPOR1S', '2NDLINE', 'AMFI', 'PAHA',\n",
       "        'AMCH', 'SPSU', 'TILAD', 'SOELD', 'STEXD', 'BOIND', 'MUSQD',\n",
       "        'PAHID', 'ARPED', 'EPTRD', 'BOSPD', 'ARADD', 'CABAD', 'BOER1D',\n",
       "        'PECT1D', 'BRAC1D', 'ACWRD', 'SPCRD', 'MOCED', 'VEEND', 'AMPAD',\n",
       "        'AMFID', 'KAPAD', 'ZIACD', 'SPORS'], dtype=object),\n",
       " 'layer1': array([nan, 'L', 'XASA', 'SPOR1', 'MUPO', 'PRGL', 'ZIGR', 'WL', 'SPOR1 ',\n",
       "        'BOER', 'XASA ', 'CABA', 'CRPO', 'SOEL', 'BOER ', 'PRGL ', 'YUEL',\n",
       "        'ATCA', 'KRLA', 'DECO', 'HOGL', 'CRPO ', 'HODR', 'SPFL', 'SPFL ',\n",
       "        'BPER', 'SPOR', 'XANT1', 'ARIS1', 'SPCO', 'DAPU', 'EUMI', 'MOCE',\n",
       "        'TILA', 'BOBA', 'BOSP', 'CAJA', 'KAPA', 'LEER', 'BOAR', 'PORT1',\n",
       "        'EUAL', 'EUSE', 'ARAD', 'PEAN', 'BRFA', 'ALIN', 'BOUT1', 'PECT1',\n",
       "        'EUDE', 'EUSR', 'EUGL', 'KALL1', 'PEPA', 'MUSQ', 'NYCT1', 'CAHU',\n",
       "        'CONMD', 'NAHI', 'ARPU', 'SELE', 'DIWI', 'PROB1', 'DANA', 'ARNE',\n",
       "        'SPIN', 'SPAI', 'BOER1', 'BRAC1', 'ERLE', 'ARPA', 'ZIAC', 'APRA',\n",
       "        'ARPE', 'BAMU', 'PASP', 'ASTE', 'DEPI', 'DYAC', 'CRYP1', 'POOL',\n",
       "        'PLPA', 'LIVE', 'POPA', 'CHIN', 'PAHI', 'EPTR', 'AMFI', 'CRPU',\n",
       "        'CRMI', 'PRGLD', 'MUPOD', 'BOERD', 'SPOR1B', 'SPOR1D', 'l',\n",
       "        'CRPOD', 'SELED', 'CRCR', 'DAPUD', 'SPFLD', 'TECO', 'DEPID',\n",
       "        'XANT1D', 'BOERB', 'APRAD', 'MUPOB', 'DIWID', 'XASAD', 'LEGO',\n",
       "        'SPCR', 'BRAR', 'ACWR', 'AMPA', 'SPSU', 'VEEN', 'TAAN', 'SPCOD',\n",
       "        'ARIS1D', 'BOBAD', 'TILAD', 'BOSPD', 'MUSQD', 'PAHID', 'SOELD',\n",
       "        'BRAC1D', 'ARPED', 'ARADD', 'SAKAD', 'VEEND', 'PECT1D', 'AMPAD'],\n",
       "       dtype=object),\n",
       " 'layer2': array([nan, 'L', 'XASA', 'WL', 'MUPO', 'SPOR1', 'XANT1', 'YUEL', 'CRPO',\n",
       "        'BOER', 'PRGL', 'BOBA', 'KAPA', 'EUMI', 'TILA', 'EUDE', 'PORT1',\n",
       "        'EUSE', 'BOSP', 'MOCE', 'EUAL', 'MUSQ', 'EUSR', 'KALL1', 'SELE',\n",
       "        'ARAD', 'DANA', 'SPFL', 'PAHI', 'BOAR', 'BRFA', 'DAPU', 'SOEL',\n",
       "        'CABA', 'PLPA', 'POPA', 'LIVE', 'BOUT1', 'PECT1', 'HODR', 'BOERD',\n",
       "        'DIWI', 'BOERB', 'PRGLD', 'MUPOD', 'XANT1D', 'PEPA', 'XASAD',\n",
       "        'POOL', 'ARPU', 'BRAR', 'VEEN', 'ACWR', 'KRLA', 'DEPID', 'SPFLD',\n",
       "        'BOBAD', 'BRAC1D', 'TILAD', 'PAHID', 'BOSPD'], dtype=object),\n",
       " 'layer3': array([nan, 'L', 'MOCE', 'CRPO', 'SPFL', 'POPA', 'KAPA', 'BOAR', 'BOBA',\n",
       "        'CABA', 'TILA', 'PEPA', 'BOER', 'BOSP', 'BOERD', 'TILAD'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{c:df[c].unique() for c in ['toplayer', 'layer1', 'layer2', 'layer3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CONMD' 'PRGLD' 'XASAD' 'SPFLD' 'SPOR1D' 'BOERD' 'ARIS1D' 'SELED' 'MUPOD'\n",
      " 'CRPOD' 'DAPUD' 'SAKAD' 'DEPID' 'YUELD' 'ARPUD' 'NAHID' 'XANT1D' 'LIVED'\n",
      " 'DIWID' 'APRAD' 'SPCOD' 'ZIGRD' 'CRYP1D' 'CRCRD' 'BAMUD' 'CAJAD' 'KRLAD'\n",
      " 'MEPUD' 'BOBAD' 'TILAD' 'SOELD' 'STEXD' 'BOIND' 'MUSQD' 'PAHID' 'ARPED'\n",
      " 'EPTRD' 'BOSPD' 'ARADD' 'CABAD' 'BOER1D' 'PECT1D' 'BRAC1D' 'ACWRD'\n",
      " 'SPCRD' 'MOCED' 'VEEND' 'AMPAD' 'AMFID' 'KAPAD' 'ZIACD']\n",
      "['CONMD' 'PRGLD' 'MUPOD' 'BOERD' 'SPOR1D' 'CRPOD' 'SELED' 'DAPUD' 'SPFLD'\n",
      " 'DEPID' 'XANT1D' 'APRAD' 'DIWID' 'XASAD' 'SPCOD' 'ARIS1D' 'BOBAD' 'TILAD'\n",
      " 'BOSPD' 'MUSQD' 'PAHID' 'SOELD' 'BRAC1D' 'ARPED' 'ARADD' 'SAKAD' 'VEEND'\n",
      " 'PECT1D' 'AMPAD']\n",
      "['BOERD' 'PRGLD' 'MUPOD' 'XANT1D' 'XASAD' 'DEPID' 'SPFLD' 'BOBAD' 'BRAC1D'\n",
      " 'TILAD' 'PAHID' 'BOSPD']\n",
      "['BOERD' 'TILAD']\n",
      "['CONMD' 'SPOR1D' 'SPFLD' 'YUELD' 'BOERD' 'ARIS1D' 'DAPUD' 'XANT1D'\n",
      " 'XASAD' 'BOBAD' 'SELED' 'SPCOD' 'ARPUD' 'MUPOD']\n"
     ]
    }
   ],
   "source": [
    "# Unique plant status patterns - change D to S or B to see others\n",
    "print(df.loc[df.toplayer.str.contains('[A-Z,1-9]{4,}D$', na=False), 'toplayer'].unique())\n",
    "print(df.loc[df.layer1.str.contains('[A-Z,1-9]{4,}D$', na=False), 'layer1'].unique())\n",
    "print(df.loc[df.layer2.str.contains('[A-Z,1-9]{4,}D$', na=False), 'layer2'].unique())\n",
    "print(df.loc[df.layer3.str.contains('[A-Z,1-9]{4,}D$', na=False), 'layer3'].unique())\n",
    "print(df.loc[df.soilsurface.str.contains('[A-Z,1-9]{4,}D$', na=False), 'soilsurface'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three cover statuses appended to some codes D, S, B\n",
    "# D=dead, S=seedling, B=black (last years growth?)\n",
    "# Find these and split out to the appropriate status column\n",
    "# Also remove some wacky spaces and lowercase letters\n",
    "for c in ['toplayer', 'layer1', 'layer2', 'layer3', 'soilsurface']:\n",
    "    # Find column values longer than 4, ending in D, S, B & modify\n",
    "    # column_status, then shorten the column value itself\n",
    "    testD = df[c].str.contains('[A-Z,1-9]{4,}D$', na=False)\n",
    "    df.loc[testD, c + '_status'] = 'D'\n",
    "    df.loc[testD, c] = df.loc[testD, c].str[0:-1]\n",
    "    testB = df[c].str.contains('[A-Z,1-9]{4,}B$', na=False)\n",
    "    df.loc[testB, c + '_status'] = 'B'\n",
    "    df.loc[testB, c] = df.loc[testB, c].str[0:-1]\n",
    "    testS = df[c].str.contains('[A-Z,1-9]{4,}S$', na=False)\n",
    "    df.loc[testS, c + '_status'] = 'S'\n",
    "    df.loc[testS, c] = df.loc[testS, c].str[0:-1]\n",
    "    # Wacky spaces and lowercase\n",
    "    df[c] = df[c].str.strip()\n",
    "    df[c] = df[c].str.upper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write\n",
    "df.to_csv(os.path.join(dest_path1,'jrn413002_lpi_data.csv'), index=False, na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-08-22 00:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.point.unique()\n",
    "df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>plot</th>\n",
       "      <th>transect</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>15</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>15</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>15</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>15</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>15</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>1698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block plot  transect  Freq\n",
       "0        1    A         1  1903\n",
       "1        1    A         2  1862\n",
       "2        1    A         3  1696\n",
       "3        1    B         1  1903\n",
       "4        1    B         2  1957\n",
       "..     ...  ...       ...   ...\n",
       "175     15    C         2  1860\n",
       "176     15    C         3  1692\n",
       "177     15    D         1  2003\n",
       "178     15    D         2  1957\n",
       "179     15    D         3  1698\n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['block', 'plot', 'transect']).size().reset_index(name='Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study                      0\n",
       "year                       0\n",
       "season                     0\n",
       "date                       0\n",
       "block                      0\n",
       "plot                       0\n",
       "transect                   0\n",
       "point                    121\n",
       "toplayer                 670\n",
       "toplayer_status       245420\n",
       "layer1                195868\n",
       "layer1_status         328271\n",
       "layer2                327016\n",
       "layer2_status         337466\n",
       "layer3                337180\n",
       "layer3_status         337744\n",
       "soilsurface              938\n",
       "soilsurface_status    334956\n",
       "comment               337001\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
